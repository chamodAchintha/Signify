{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signjoey.helpers import (\n",
    "    load_config,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from signjoey.data import load_data, make_data_iter\n",
    "from signjoey.model import build_model\n",
    "from signjoey.batch import Batch\n",
    "from torchtext.data import Dataset\n",
    "from signjoey.vocabulary import (\n",
    "    TextVocabulary,\n",
    "    GlossVocabulary,\n",
    "    PAD_TOKEN,\n",
    "    EOS_TOKEN,\n",
    "    BOS_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = 'configs/example.yaml'\n",
    "ckpt = 'output/best-kaggle.ckpt'\n",
    "\n",
    "cfg = load_config(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data, gls_vocab, txt_vocab = load_data(data_cfg=cfg[\"data\"])\n",
    "del train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <torchtext.data.field.RawField at 0x172fa0c9390>,\n",
       " 'signer': <torchtext.data.field.RawField at 0x172fa0c8550>,\n",
       " 'sgn': <torchtext.data.field.Field at 0x172fa0c8880>,\n",
       " 'gls': <torchtext.data.field.Field at 0x172fa0c8e20>,\n",
       " 'txt': <torchtext.data.field.Field at 0x172fa0c8400>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['dev/11August_2010_Wednesday_tagesschau-2', 'Signer08', [tensor([4.1970e-01, 1.7552e+00, 2.4212e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([2.3592e+00, 2.2639e+00, 4.4332e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([5.0251e+00, 2.1903e+00, 1.3583e-01,  ..., 5.7079e-02, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([5.3371e+00, 1.3213e+00, 1.0000e-08,  ..., 2.1011e+00, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([4.2258e+00, 2.5479e+00, 1.0000e-08,  ..., 8.2129e-01, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([3.6651e+00, 3.7671e+00, 1.0000e-08,  ..., 3.9290e-01, 1.0000e-08,\n",
       "        1.0818e-01]), tensor([3.1189e+00, 3.1486e+00, 1.0000e-08,  ..., 1.8473e-01, 1.0000e-08,\n",
       "        1.0979e+00]), tensor([4.0009e+00, 3.6177e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        2.3070e+00]), tensor([4.9496e+00, 3.4256e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        2.5931e+00]), tensor([6.0652e+00, 3.4525e+00, 4.0531e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        2.8201e+00]), tensor([5.3373e+00, 3.8509e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        9.5385e-01]), tensor([4.5486e+00, 4.0457e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        5.4798e-01]), tensor([5.0322e+00, 3.4887e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        3.4340e-01]), tensor([3.8630e+00, 1.6207e+00, 3.3798e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        1.0000e-08]), tensor([3.9027e+00, 9.3721e-01, 2.7966e-01,  ..., 2.8720e-01, 1.0000e-08,\n",
       "        2.5798e-02]), tensor([5.0523e+00, 1.5720e+00, 2.7351e+00,  ..., 2.0549e+00, 1.0000e-08,\n",
       "        1.5039e-01]), tensor([5.3673e+00, 2.1393e+00, 1.7223e+00,  ..., 3.0321e+00, 1.0000e-08,\n",
       "        4.3680e+00]), tensor([4.2105e+00, 2.9326e+00, 9.8246e-01,  ..., 3.4310e+00, 1.0000e-08,\n",
       "        4.6791e+00]), tensor([1.5416e+00, 1.8263e+00, 7.6024e-01,  ..., 6.5362e+00, 1.0000e-08,\n",
       "        6.8335e+00]), tensor([1.8499e+00, 1.5001e+00, 3.2110e-01,  ..., 6.1666e+00, 1.0000e-08,\n",
       "        7.6189e+00]), tensor([1.6744e+00, 1.4740e+00, 2.4506e-01,  ..., 5.8991e+00, 1.0000e-08,\n",
       "        8.1201e+00]), tensor([1.8916e+00, 2.0929e+00, 2.9696e-01,  ..., 5.4092e+00, 1.0000e-08,\n",
       "        8.8746e+00]), tensor([8.2353e-01, 1.1429e+00, 2.0991e+00,  ..., 8.3160e+00, 1.0000e-08,\n",
       "        8.7264e+00]), tensor([2.5637e+00, 2.0289e-01, 2.6594e+00,  ..., 8.9495e+00, 1.0000e-08,\n",
       "        6.2958e+00]), tensor([1.2964e+00, 1.2275e-01, 5.6700e-01,  ..., 5.4911e+00, 1.0000e-08,\n",
       "        3.7056e+00]), tensor([2.4741e+00, 8.7676e-02, 2.0767e+00,  ..., 6.5606e+00, 1.0000e-08,\n",
       "        7.7454e+00]), tensor([2.9268e+00, 1.9962e-01, 2.0774e+00,  ..., 6.0295e+00, 1.0000e-08,\n",
       "        5.3345e+00]), tensor([3.8959e+00, 1.2467e+00, 6.7496e-01,  ..., 5.0748e+00, 1.0000e-08,\n",
       "        6.1203e+00]), tensor([5.1840e+00, 2.7911e+00, 3.3104e-01,  ..., 3.1106e+00, 1.0000e-08,\n",
       "        9.0426e+00]), tensor([6.2028e+00, 3.1138e+00, 1.2384e+00,  ..., 1.7266e+00, 1.0000e-08,\n",
       "        7.8694e+00]), tensor([4.2778e+00, 3.2083e+00, 5.1601e-01,  ..., 1.3308e-01, 1.0000e-08,\n",
       "        7.7240e+00]), tensor([3.8686e+00, 2.4097e+00, 1.0626e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        7.7580e+00]), tensor([4.2171e+00, 3.6156e+00, 2.1440e-03,  ..., 1.0000e-08, 1.0000e-08,\n",
       "        7.5999e+00]), tensor([4.5998e+00, 3.8369e+00, 1.0000e-08,  ..., 1.0000e-08, 3.0555e-02,\n",
       "        6.2586e+00]), tensor([3.5037e+00, 4.5816e+00, 7.3963e-02,  ..., 1.0000e-08, 1.8023e-01,\n",
       "        6.7953e+00]), tensor([4.5763e-01, 4.6373e+00, 1.1641e+00,  ..., 5.7903e-01, 1.0000e-08,\n",
       "        1.2964e+01]), tensor([7.5301e-02, 3.5815e+00, 1.2494e+00,  ..., 5.8662e-01, 1.0000e-08,\n",
       "        1.2568e+01]), tensor([1.0000e-08, 3.0473e+00, 1.6536e+00,  ..., 8.7356e-02, 1.0000e-08,\n",
       "        7.8441e+00]), tensor([1.0000e-08, 3.4787e+00, 2.6433e+00,  ..., 3.6423e-02, 1.0000e-08,\n",
       "        6.4863e+00]), tensor([1.0000e-08, 3.4036e+00, 3.5074e+00,  ..., 4.1921e-02, 1.0000e-08,\n",
       "        5.6587e+00]), tensor([1.8123e-01, 4.3320e+00, 3.1511e+00,  ..., 3.2355e-01, 1.0000e-08,\n",
       "        2.6719e+00]), tensor([4.7317e-01, 4.3573e+00, 3.0296e+00,  ..., 4.7304e-01, 1.0000e-08,\n",
       "        1.8732e+00])], ['DRUCK', 'TIEF', 'KOMMEN'], ['tiefer', 'luftdruck', 'bestimmt', 'in', 'den', 'nÃ¤chsten', 'tagen', 'unser', 'wetter', '.']])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data[0].__dict__.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_config = cfg[\"training\"]\n",
    "\n",
    "valid_iter = make_data_iter(\n",
    "    dev_data,\n",
    "    batch_size=train_config['batch_size'],\n",
    "    batch_type=train_config['batch_type'],\n",
    "    train=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_subsampling_ratio = cfg[\"data\"].get(\n",
    "    \"frame_subsampling_ratio\", None\n",
    ")\n",
    "random_frame_subsampling = cfg[\"data\"].get(\n",
    "    \"random_frame_subsampling\", None\n",
    ")\n",
    "random_frame_masking_ratio = cfg[\"data\"].get(\n",
    "    \"random_frame_masking_ratio\", None\n",
    ")\n",
    "txt_pad_idx = txt_vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torchtext\\data\\field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    }
   ],
   "source": [
    "for batch in iter(valid_iter):\n",
    "    # reactivate training\n",
    "    # create a Batch object from torchtext batch\n",
    "    batch = Batch(\n",
    "        is_train=False,\n",
    "        torch_batch=batch,\n",
    "        txt_pad_index= txt_pad_idx,\n",
    "        sgn_dim=cfg['data']['feature_size'],\n",
    "        use_cuda=False,\n",
    "        frame_subsampling_ratio=frame_subsampling_ratio,\n",
    "        random_frame_subsampling=random_frame_subsampling,\n",
    "        random_frame_masking_ratio=random_frame_masking_ratio,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165, 1024])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.sgn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 165)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.sgn_mask), len(batch.sgn_mask[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.sgn_mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "filename = 'data/phoenix14t.pami0.dev'\n",
    "\n",
    "\n",
    "with gzip.open(filename, \"rb\") as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 1024])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_object[0]['sign'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(640)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "i = -1\n",
    "\n",
    "(loaded_object[0]['sign'][i] != torch.zeros(loaded_object[0]['sign'][i].shape)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = load_checkpoint(ckpt, use_cuda=False)\n",
    "\n",
    "do_recognition = cfg[\"training\"].get(\"recognition_loss_weight\", 1.0) > 0.0\n",
    "do_translation = cfg[\"training\"].get(\"translation_loss_weight\", 1.0) > 0.0\n",
    "\n",
    "model = build_model(\n",
    "    cfg=cfg[\"model\"],\n",
    "    gls_vocab=gls_vocab,\n",
    "    txt_vocab=txt_vocab,\n",
    "    sgn_dim=sum(cfg[\"data\"][\"feature_size\"])\n",
    "    if isinstance(cfg[\"data\"][\"feature_size\"], list)\n",
    "    else cfg[\"data\"][\"feature_size\"],\n",
    "    do_recognition=do_recognition,\n",
    "    do_translation=do_translation,\n",
    "    ensemble=False,\n",
    "    ensembleN=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_checkpoint[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialEmbeddings(embedding_dim=512, input_size=1024)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sgn_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.sgn_embed(batch.sgn, batch.sgn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 165, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.encoder(embeddings, batch.sgn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2181,  0.5392,  0.2666,  ...,  1.9912, -0.2534, -0.1238],\n",
       "         [ 0.3249, -0.1509, -0.1520,  ...,  1.1652, -0.1434, -0.0041],\n",
       "         [ 0.3100, -0.1471, -0.3730,  ...,  0.5793, -1.0380,  1.2287],\n",
       "         ...,\n",
       "         [-0.1267, -0.1866,  1.0359,  ...,  0.8788, -0.9316, -0.5963],\n",
       "         [-0.5408,  0.4729,  0.1245,  ...,  0.9377, -0.9623, -0.9559],\n",
       "         [ 0.4522, -0.1276,  0.4823,  ...,  0.0464, -1.4490, -1.3038]],\n",
       "\n",
       "        [[-0.0720, -0.3846, -0.0576,  ...,  0.0783, -0.3989, -0.2873],\n",
       "         [-0.0642, -0.6298,  0.1268,  ...,  0.0550, -0.0311, -0.1896],\n",
       "         [-0.0707, -1.0677,  0.3072,  ...,  0.1430, -0.4266, -0.3633],\n",
       "         ...,\n",
       "         [-0.0641,  0.4085, -0.3759,  ...,  0.6881, -0.3928, -0.4809],\n",
       "         [-0.2206, -0.2361, -0.1940,  ...,  0.0339, -1.2790, -0.4826],\n",
       "         [ 0.5658, -0.4308, -0.1457,  ...,  0.3657, -1.2463,  0.0250]],\n",
       "\n",
       "        [[-0.0565, -0.3880, -0.7907,  ...,  0.4861,  0.4019,  0.4380],\n",
       "         [ 0.4766, -0.4889, -0.2924,  ...,  0.3148,  0.4123,  0.4231],\n",
       "         [ 0.3295, -1.0055,  0.2661,  ..., -0.4160, -0.0528, -0.4775],\n",
       "         ...,\n",
       "         [-0.0400,  0.5314, -0.0582,  ...,  0.2239,  0.0318,  0.1377],\n",
       "         [-0.0244, -0.1949,  0.4550,  ...,  0.7360, -0.5044, -0.6235],\n",
       "         [ 0.1646,  0.0212,  0.2558,  ...,  0.6634, -0.9266, -0.2732]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7585, -0.2863,  0.5071,  ...,  0.7273, -0.2222,  0.2693],\n",
       "         [ 0.4853, -0.7034,  0.3782,  ...,  0.4497, -0.8969, -0.5925],\n",
       "         [ 0.6922, -0.2484,  0.2084,  ...,  0.2290, -0.6863, -0.7183],\n",
       "         ...,\n",
       "         [ 0.1479,  0.3285, -0.0763,  ...,  0.4641,  0.3504, -0.1051],\n",
       "         [ 0.1875, -0.4645,  0.5079,  ...,  1.0077, -0.8103, -0.2312],\n",
       "         [ 0.6188,  0.7362,  0.0075,  ...,  0.4246,  0.4399, -0.2634]],\n",
       "\n",
       "        [[-0.0303,  0.2025, -0.3722,  ...,  1.6730,  0.0992,  0.5712],\n",
       "         [ 0.3112, -0.1726,  0.1051,  ...,  1.4253,  0.0187,  0.5365],\n",
       "         [-0.1088, -0.9325,  0.4555,  ...,  1.0280,  0.1196,  0.6920],\n",
       "         ...,\n",
       "         [ 0.2154,  0.1672, -0.0554,  ...,  0.9335, -0.6560, -0.1175],\n",
       "         [-0.4334,  0.8140, -0.4503,  ...,  0.2802, -0.4592, -0.1937],\n",
       "         [ 0.3120,  0.5075,  0.3779,  ...,  1.3921, -0.1887, -0.5255]],\n",
       "\n",
       "        [[-0.0755,  0.5089,  0.5487,  ..., -0.0191, -0.1367,  0.1760],\n",
       "         [-0.2110, -0.4558,  0.3050,  ..., -0.1187,  0.3173, -0.1815],\n",
       "         [-0.3764, -0.2957,  0.2602,  ..., -0.2752, -0.1376, -0.1739],\n",
       "         ...,\n",
       "         [-0.1897, -0.2627,  0.2242,  ...,  0.8934, -0.4191,  0.1289],\n",
       "         [ 0.0913,  0.1995,  0.7734,  ...,  0.4914, -0.7355, -1.0469],\n",
       "         [ 0.5259, -0.0515,  0.4599,  ...,  0.5349, -1.1529, -0.9801]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 165, 512])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
