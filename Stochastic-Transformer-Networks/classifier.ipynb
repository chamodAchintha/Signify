{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signjoey.helpers import (\n",
    "    load_config,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from signjoey.data import load_data\n",
    "from signjoey.model import build_model\n",
    "\n",
    "\n",
    "cfg_file = 'configs/example.yaml'\n",
    "ckpt = 'output/best-kaggle.ckpt'\n",
    "\n",
    "cfg = load_config(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torch\\_utils.py:133: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  t = torch.tensor([], dtype=storage.dtype, device=storage._untyped().device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = load_checkpoint(ckpt, use_cuda=False)\n",
    "\n",
    "do_recognition = cfg[\"training\"].get(\"recognition_loss_weight\", 1.0) > 0.0\n",
    "do_translation = cfg[\"training\"].get(\"translation_loss_weight\", 1.0) > 0.0\n",
    "\n",
    "_, dev_data, test_data, gls_vocab, txt_vocab = load_data(data_cfg=cfg[\"data\"])\n",
    "\n",
    "model = build_model(\n",
    "    cfg=cfg[\"model\"],\n",
    "    gls_vocab=gls_vocab,\n",
    "    txt_vocab=txt_vocab,\n",
    "    sgn_dim=sum(cfg[\"data\"][\"feature_size\"])\n",
    "    if isinstance(cfg[\"data\"][\"feature_size\"], list)\n",
    "    else cfg[\"data\"][\"feature_size\"],\n",
    "    do_recognition=do_recognition,\n",
    "    do_translation=do_translation,\n",
    "    ensemble=False,\n",
    "    ensembleN=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "filename = 'data/phoenix14t.pami0.train'\n",
    "\n",
    "\n",
    "with gzip.open(filename, \"rb\") as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_object[0][\"sign\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'train/29September_2010_Wednesday_heute-5458', 'signer': 'Signer07', 'gloss': 'MORGEN FRUEH FLUSS REGEN MORGEN S STEIN BIS SACHSEN REGION OFT SONNE TROCKEN FREUNDLICH DAFUER WEST ANFANG REGEN ABEND WAHRSCHEINLICH E REGION BIS ALLGAEU REGION REGEN', 'text': 'morgen scheint dann von schleswig holstein bis nach sachsen häufig die sonne es bleibt trocken während es im westen anfängt zu regnen und abends regnet es dann etwa so vom emsland bis zum allgäu .', 'sign': tensor([[0.0732, 0.2189, 0.3328,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0489, 0.4065,  ..., 0.3054, 0.0000, 0.3405],\n",
      "        [0.0322, 1.0775, 0.3299,  ..., 0.6737, 0.0000, 0.9411],\n",
      "        ...,\n",
      "        [0.0000, 0.2249, 0.6509,  ..., 0.7619, 0.0000, 0.3435],\n",
      "        [0.0000, 0.5764, 0.8349,  ..., 0.7944, 0.0000, 0.0497],\n",
      "        [0.0000, 0.3482, 0.6576,  ..., 1.8677, 0.0000, 0.2705]])}\n"
     ]
    }
   ],
   "source": [
    "max_seq_d = loaded_object[0]\n",
    "for d in loaded_object:\n",
    "    if len(d[\"sign\"])>400:\n",
    "        continue\n",
    "    if len(d[\"sign\"])>len(max_seq_d['sign']):\n",
    "        max_seq_d = d\n",
    "print(max_seq_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([395, 1024])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_d['sign'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([86, 1024])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_object[0]['sign'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_object[0]['sign'][0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'sequence': 'dev/11August_2010_Wednesday_tagesschau-2',\n",
       "              'signer': 'Signer08',\n",
       "              'sgn': [tensor([4.1970e-01, 1.7552e+00, 2.4212e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([2.3592e+00, 2.2639e+00, 4.4332e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([5.0251e+00, 2.1903e+00, 1.3583e-01,  ..., 5.7079e-02, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([5.3371e+00, 1.3213e+00, 1.0000e-08,  ..., 2.1011e+00, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([4.2258e+00, 2.5479e+00, 1.0000e-08,  ..., 8.2129e-01, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([3.6651e+00, 3.7671e+00, 1.0000e-08,  ..., 3.9290e-01, 1.0000e-08,\n",
       "                       1.0818e-01]),\n",
       "               tensor([3.1189e+00, 3.1486e+00, 1.0000e-08,  ..., 1.8473e-01, 1.0000e-08,\n",
       "                       1.0979e+00]),\n",
       "               tensor([4.0009e+00, 3.6177e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       2.3070e+00]),\n",
       "               tensor([4.9496e+00, 3.4256e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       2.5931e+00]),\n",
       "               tensor([6.0652e+00, 3.4525e+00, 4.0531e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       2.8201e+00]),\n",
       "               tensor([5.3373e+00, 3.8509e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       9.5385e-01]),\n",
       "               tensor([4.5486e+00, 4.0457e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       5.4798e-01]),\n",
       "               tensor([5.0322e+00, 3.4887e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       3.4340e-01]),\n",
       "               tensor([3.8630e+00, 1.6207e+00, 3.3798e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       1.0000e-08]),\n",
       "               tensor([3.9027e+00, 9.3721e-01, 2.7966e-01,  ..., 2.8720e-01, 1.0000e-08,\n",
       "                       2.5798e-02]),\n",
       "               tensor([5.0523e+00, 1.5720e+00, 2.7351e+00,  ..., 2.0549e+00, 1.0000e-08,\n",
       "                       1.5039e-01]),\n",
       "               tensor([5.3673e+00, 2.1393e+00, 1.7223e+00,  ..., 3.0321e+00, 1.0000e-08,\n",
       "                       4.3680e+00]),\n",
       "               tensor([4.2105e+00, 2.9326e+00, 9.8246e-01,  ..., 3.4310e+00, 1.0000e-08,\n",
       "                       4.6791e+00]),\n",
       "               tensor([1.5416e+00, 1.8263e+00, 7.6024e-01,  ..., 6.5362e+00, 1.0000e-08,\n",
       "                       6.8335e+00]),\n",
       "               tensor([1.8499e+00, 1.5001e+00, 3.2110e-01,  ..., 6.1666e+00, 1.0000e-08,\n",
       "                       7.6189e+00]),\n",
       "               tensor([1.6744e+00, 1.4740e+00, 2.4506e-01,  ..., 5.8991e+00, 1.0000e-08,\n",
       "                       8.1201e+00]),\n",
       "               tensor([1.8916e+00, 2.0929e+00, 2.9696e-01,  ..., 5.4092e+00, 1.0000e-08,\n",
       "                       8.8746e+00]),\n",
       "               tensor([8.2353e-01, 1.1429e+00, 2.0991e+00,  ..., 8.3160e+00, 1.0000e-08,\n",
       "                       8.7264e+00]),\n",
       "               tensor([2.5637e+00, 2.0289e-01, 2.6594e+00,  ..., 8.9495e+00, 1.0000e-08,\n",
       "                       6.2958e+00]),\n",
       "               tensor([1.2964e+00, 1.2275e-01, 5.6700e-01,  ..., 5.4911e+00, 1.0000e-08,\n",
       "                       3.7056e+00]),\n",
       "               tensor([2.4741e+00, 8.7676e-02, 2.0767e+00,  ..., 6.5606e+00, 1.0000e-08,\n",
       "                       7.7454e+00]),\n",
       "               tensor([2.9268e+00, 1.9962e-01, 2.0774e+00,  ..., 6.0295e+00, 1.0000e-08,\n",
       "                       5.3345e+00]),\n",
       "               tensor([3.8959e+00, 1.2467e+00, 6.7496e-01,  ..., 5.0748e+00, 1.0000e-08,\n",
       "                       6.1203e+00]),\n",
       "               tensor([5.1840e+00, 2.7911e+00, 3.3104e-01,  ..., 3.1106e+00, 1.0000e-08,\n",
       "                       9.0426e+00]),\n",
       "               tensor([6.2028e+00, 3.1138e+00, 1.2384e+00,  ..., 1.7266e+00, 1.0000e-08,\n",
       "                       7.8694e+00]),\n",
       "               tensor([4.2778e+00, 3.2083e+00, 5.1601e-01,  ..., 1.3308e-01, 1.0000e-08,\n",
       "                       7.7240e+00]),\n",
       "               tensor([3.8686e+00, 2.4097e+00, 1.0626e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       7.7580e+00]),\n",
       "               tensor([4.2171e+00, 3.6156e+00, 2.1440e-03,  ..., 1.0000e-08, 1.0000e-08,\n",
       "                       7.5999e+00]),\n",
       "               tensor([4.5998e+00, 3.8369e+00, 1.0000e-08,  ..., 1.0000e-08, 3.0555e-02,\n",
       "                       6.2586e+00]),\n",
       "               tensor([3.5037e+00, 4.5816e+00, 7.3963e-02,  ..., 1.0000e-08, 1.8023e-01,\n",
       "                       6.7953e+00]),\n",
       "               tensor([4.5763e-01, 4.6373e+00, 1.1641e+00,  ..., 5.7903e-01, 1.0000e-08,\n",
       "                       1.2964e+01]),\n",
       "               tensor([7.5301e-02, 3.5815e+00, 1.2494e+00,  ..., 5.8662e-01, 1.0000e-08,\n",
       "                       1.2568e+01]),\n",
       "               tensor([1.0000e-08, 3.0473e+00, 1.6536e+00,  ..., 8.7356e-02, 1.0000e-08,\n",
       "                       7.8441e+00]),\n",
       "               tensor([1.0000e-08, 3.4787e+00, 2.6433e+00,  ..., 3.6423e-02, 1.0000e-08,\n",
       "                       6.4863e+00]),\n",
       "               tensor([1.0000e-08, 3.4036e+00, 3.5074e+00,  ..., 4.1921e-02, 1.0000e-08,\n",
       "                       5.6587e+00]),\n",
       "               tensor([1.8123e-01, 4.3320e+00, 3.1511e+00,  ..., 3.2355e-01, 1.0000e-08,\n",
       "                       2.6719e+00]),\n",
       "               tensor([4.7317e-01, 4.3573e+00, 3.0296e+00,  ..., 4.7304e-01, 1.0000e-08,\n",
       "                       1.8732e+00])],\n",
       "              'gls': ['DRUCK', 'TIEF', 'KOMMEN'],\n",
       "              'txt': ['tiefer',\n",
       "               'luftdruck',\n",
       "               'bestimmt',\n",
       "               'in',\n",
       "               'den',\n",
       "               'nächsten',\n",
       "               'tagen',\n",
       "               'unser',\n",
       "               'wetter',\n",
       "               '.']})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_data[0].__dict__.values().mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <torchtext.data.field.RawField at 0x1a9f7e0e1a0>,\n",
       " 'signer': <torchtext.data.field.RawField at 0x1a9f7e23400>,\n",
       " 'sgn': <torchtext.data.field.Field at 0x1a9f7e20ac0>,\n",
       " 'gls': <torchtext.data.field.Field at 0x1a9f7e21f60>,\n",
       " 'txt': <torchtext.data.field.Field at 0x1a9f7e20970>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignModel(\n",
       "\tencoder=TransformerEncoder(num_layers=2, num_heads=8),\n",
       "\tdecoder=TransformerDecoder(num_layers=2, num_heads=8),\n",
       "\tsgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1024),\n",
       "\ttxt_embed=Embeddings(embedding_dim=512, vocab_size=2892))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_checkpoint[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialEmbeddings(embedding_dim=512, input_size=1024)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sgn_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(num_layers=2, num_heads=8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SignModel(\n",
       "\tencoder=TransformerEncoder(num_layers=2, num_heads=8),\n",
       "\tdecoder=TransformerDecoder(num_layers=2, num_heads=8),\n",
       "\tsgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1024),\n",
       "\ttxt_embed=Embeddings(embedding_dim=512, vocab_size=2892))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: encoder.layers.0.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.src_src_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.0.posterior_mean | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.0.posterior_un_scale | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.0.bias_mean | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.0.bias_un_scale | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.2.posterior_mean | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.2.posterior_un_scale | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.2.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.0.feed_forward.pwff_layer.2.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.src_src_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.0.posterior_mean | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.0.posterior_un_scale | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.0.bias_mean | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.0.bias_un_scale | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.2.posterior_mean | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.2.posterior_un_scale | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.2.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layers.1.feed_forward.pwff_layer.2.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: encoder.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.trg_trg_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.src_trg_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.0.posterior_mean | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.0.posterior_un_scale | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.0.bias_mean | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.0.bias_un_scale | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.2.posterior_mean | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.2.posterior_un_scale | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.2.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.feed_forward.pwff_layer.2.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.x_layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.x_layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.dec_layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.0.dec_layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.trg_trg_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.k_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.k_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.k_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.k_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.v_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.v_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.v_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.v_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.q_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.q_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.q_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.q_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.output_layer.posterior_mean | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.output_layer.posterior_un_scale | Shape: torch.Size([512, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.output_layer.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.src_trg_att.output_layer.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.0.posterior_mean | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.0.posterior_un_scale | Shape: torch.Size([2048, 512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.0.bias_mean | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.0.bias_un_scale | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.2.posterior_mean | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.2.posterior_un_scale | Shape: torch.Size([512, 2048]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.2.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.feed_forward.pwff_layer.2.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.x_layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.x_layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.dec_layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layers.1.dec_layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layer_norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.layer_norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.output_layer.posterior_mean | Shape: torch.Size([2892, 512]) | Requires Grad: True\n",
      "Layer: decoder.output_layer.posterior_un_scale | Shape: torch.Size([2892, 512]) | Requires Grad: True\n",
      "Layer: decoder.output_layer.bias_mean | Shape: torch.Size([2892]) | Requires Grad: True\n",
      "Layer: decoder.output_layer.bias_un_scale | Shape: torch.Size([2892]) | Requires Grad: True\n",
      "Layer: sgn_embed.ln.posterior_mean | Shape: torch.Size([512, 1024]) | Requires Grad: True\n",
      "Layer: sgn_embed.ln.posterior_un_scale | Shape: torch.Size([512, 1024]) | Requires Grad: True\n",
      "Layer: sgn_embed.ln.bias_mean | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: sgn_embed.ln.bias_un_scale | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: sgn_embed.norm.norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: sgn_embed.norm.norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: txt_embed.lut.weight | Shape: torch.Size([2892, 512]) | Requires Grad: True\n",
      "Layer: txt_embed.norm.norm.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: txt_embed.norm.norm.bias | Shape: torch.Size([512]) | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Shape: {param.shape} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4.1970e-01, 1.7552e+00, 2.4212e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([2.3592e+00, 2.2639e+00, 4.4332e-01,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([5.0251e+00, 2.1903e+00, 1.3583e-01,  ..., 5.7079e-02, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([5.3371e+00, 1.3213e+00, 1.0000e-08,  ..., 2.1011e+00, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([4.2258e+00, 2.5479e+00, 1.0000e-08,  ..., 8.2129e-01, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([3.6651e+00, 3.7671e+00, 1.0000e-08,  ..., 3.9290e-01, 1.0000e-08,\n",
       "         1.0818e-01]),\n",
       " tensor([3.1189e+00, 3.1486e+00, 1.0000e-08,  ..., 1.8473e-01, 1.0000e-08,\n",
       "         1.0979e+00]),\n",
       " tensor([4.0009e+00, 3.6177e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         2.3070e+00]),\n",
       " tensor([4.9496e+00, 3.4256e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         2.5931e+00]),\n",
       " tensor([6.0652e+00, 3.4525e+00, 4.0531e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         2.8201e+00]),\n",
       " tensor([5.3373e+00, 3.8509e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         9.5385e-01]),\n",
       " tensor([4.5486e+00, 4.0457e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         5.4798e-01]),\n",
       " tensor([5.0322e+00, 3.4887e+00, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         3.4340e-01]),\n",
       " tensor([3.8630e+00, 1.6207e+00, 3.3798e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         1.0000e-08]),\n",
       " tensor([3.9027e+00, 9.3721e-01, 2.7966e-01,  ..., 2.8720e-01, 1.0000e-08,\n",
       "         2.5798e-02]),\n",
       " tensor([5.0523e+00, 1.5720e+00, 2.7351e+00,  ..., 2.0549e+00, 1.0000e-08,\n",
       "         1.5039e-01]),\n",
       " tensor([5.3673e+00, 2.1393e+00, 1.7223e+00,  ..., 3.0321e+00, 1.0000e-08,\n",
       "         4.3680e+00]),\n",
       " tensor([4.2105e+00, 2.9326e+00, 9.8246e-01,  ..., 3.4310e+00, 1.0000e-08,\n",
       "         4.6791e+00]),\n",
       " tensor([1.5416e+00, 1.8263e+00, 7.6024e-01,  ..., 6.5362e+00, 1.0000e-08,\n",
       "         6.8335e+00]),\n",
       " tensor([1.8499e+00, 1.5001e+00, 3.2110e-01,  ..., 6.1666e+00, 1.0000e-08,\n",
       "         7.6189e+00]),\n",
       " tensor([1.6744e+00, 1.4740e+00, 2.4506e-01,  ..., 5.8991e+00, 1.0000e-08,\n",
       "         8.1201e+00]),\n",
       " tensor([1.8916e+00, 2.0929e+00, 2.9696e-01,  ..., 5.4092e+00, 1.0000e-08,\n",
       "         8.8746e+00]),\n",
       " tensor([8.2353e-01, 1.1429e+00, 2.0991e+00,  ..., 8.3160e+00, 1.0000e-08,\n",
       "         8.7264e+00]),\n",
       " tensor([2.5637e+00, 2.0289e-01, 2.6594e+00,  ..., 8.9495e+00, 1.0000e-08,\n",
       "         6.2958e+00]),\n",
       " tensor([1.2964e+00, 1.2275e-01, 5.6700e-01,  ..., 5.4911e+00, 1.0000e-08,\n",
       "         3.7056e+00]),\n",
       " tensor([2.4741e+00, 8.7676e-02, 2.0767e+00,  ..., 6.5606e+00, 1.0000e-08,\n",
       "         7.7454e+00]),\n",
       " tensor([2.9268e+00, 1.9962e-01, 2.0774e+00,  ..., 6.0295e+00, 1.0000e-08,\n",
       "         5.3345e+00]),\n",
       " tensor([3.8959e+00, 1.2467e+00, 6.7496e-01,  ..., 5.0748e+00, 1.0000e-08,\n",
       "         6.1203e+00]),\n",
       " tensor([5.1840e+00, 2.7911e+00, 3.3104e-01,  ..., 3.1106e+00, 1.0000e-08,\n",
       "         9.0426e+00]),\n",
       " tensor([6.2028e+00, 3.1138e+00, 1.2384e+00,  ..., 1.7266e+00, 1.0000e-08,\n",
       "         7.8694e+00]),\n",
       " tensor([4.2778e+00, 3.2083e+00, 5.1601e-01,  ..., 1.3308e-01, 1.0000e-08,\n",
       "         7.7240e+00]),\n",
       " tensor([3.8686e+00, 2.4097e+00, 1.0626e-02,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         7.7580e+00]),\n",
       " tensor([4.2171e+00, 3.6156e+00, 2.1440e-03,  ..., 1.0000e-08, 1.0000e-08,\n",
       "         7.5999e+00]),\n",
       " tensor([4.5998e+00, 3.8369e+00, 1.0000e-08,  ..., 1.0000e-08, 3.0555e-02,\n",
       "         6.2586e+00]),\n",
       " tensor([3.5037e+00, 4.5816e+00, 7.3963e-02,  ..., 1.0000e-08, 1.8023e-01,\n",
       "         6.7953e+00]),\n",
       " tensor([4.5763e-01, 4.6373e+00, 1.1641e+00,  ..., 5.7903e-01, 1.0000e-08,\n",
       "         1.2964e+01]),\n",
       " tensor([7.5301e-02, 3.5815e+00, 1.2494e+00,  ..., 5.8662e-01, 1.0000e-08,\n",
       "         1.2568e+01]),\n",
       " tensor([1.0000e-08, 3.0473e+00, 1.6536e+00,  ..., 8.7356e-02, 1.0000e-08,\n",
       "         7.8441e+00]),\n",
       " tensor([1.0000e-08, 3.4787e+00, 2.6433e+00,  ..., 3.6423e-02, 1.0000e-08,\n",
       "         6.4863e+00]),\n",
       " tensor([1.0000e-08, 3.4036e+00, 3.5074e+00,  ..., 4.1921e-02, 1.0000e-08,\n",
       "         5.6587e+00]),\n",
       " tensor([1.8123e-01, 4.3320e+00, 3.1511e+00,  ..., 3.2355e-01, 1.0000e-08,\n",
       "         2.6719e+00]),\n",
       " tensor([4.7317e-01, 4.3573e+00, 3.0296e+00,  ..., 4.7304e-01, 1.0000e-08,\n",
       "         1.8732e+00])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data[0].__dict__[\"sgn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signjoey.data import load_data, make_data_iter\n",
    "from signjoey.batch import Batch\n",
    "\n",
    "valid_iter = make_data_iter(\n",
    "    dataset=dev_data,\n",
    "    batch_size=32,\n",
    "    batch_type=\"word\",\n",
    "    shuffle=False,\n",
    "    train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.sequence]:['dev/11August_2010_Wednesday_tagesschau-2', 'dev/11August_2010_Wednesday_tagesschau-3', 'dev/11August_2010_Wednesday_tagesschau-8', 'dev/25October_2010_Monday_tagesschau-22', 'dev/05May_2011_Thursday_tagesschau-25', 'dev/15December_2010_Wednesday_tagesschau-40', 'dev/10March_2011_Thursday_heute-51', 'dev/14August_2009_Friday_tagesschau-72', 'dev/26January_2010_Tuesday_heute-107', 'dev/12February_2010_Friday_tagesschau-125', 'dev/12February_2010_Friday_tagesschau-126', 'dev/01November_2010_Monday_tagesschau-140', 'dev/28November_2011_Monday_tagesschau-165', 'dev/28November_2011_Monday_tagesschau-168', 'dev/28November_2011_Monday_tagesschau-172', 'dev/24November_2011_Thursday_heute-222', 'dev/24November_2011_Thursday_heute-223', 'dev/19October_2009_Monday_tagesschau-229', 'dev/12July_2010_Monday_heute-244', 'dev/21August_2011_Sunday_tagesschau-264', 'dev/21August_2011_Sunday_tagesschau-265', 'dev/22November_2010_Monday_heute-279', 'dev/14October_2010_Thursday_tagesschau-298', 'dev/14October_2010_Thursday_tagesschau-299', 'dev/06April_2010_Tuesday_tagesschau-308', 'dev/12May_2010_Wednesday_tagesschau-318', 'dev/17April_2010_Saturday_tagesschau-396', 'dev/01October_2009_Thursday_tagesschau-417', 'dev/04May_2010_Tuesday_heute-453', 'dev/30January_2013_Wednesday_tagesschau-475', 'dev/30January_2013_Wednesday_tagesschau-477', 'dev/14October_2009_Wednesday_tagesschau-529']\n",
      "\t[.signer]:['Signer08', 'Signer08', 'Signer08', 'Signer01', 'Signer08', 'Signer05', 'Signer01', 'Signer05', 'Signer03', 'Signer09', 'Signer09', 'Signer05', 'Signer07', 'Signer07', 'Signer07', 'Signer05', 'Signer05', 'Signer09', 'Signer01', 'Signer08', 'Signer08', 'Signer01', 'Signer07', 'Signer07', 'Signer03', 'Signer01', 'Signer03', 'Signer03', 'Signer04', 'Signer05', 'Signer05', 'Signer01']\n",
      "\t[.sgn]:('[torch.FloatTensor of size 32x165x1024]', '[torch.FloatTensor of size 32]')\n",
      "\t[.gls]:('[torch.LongTensor of size 32x14]', '[torch.LongTensor of size 32]')\n",
      "\t[.txt]:('[torch.LongTensor of size 32x30]', '[torch.LongTensor of size 32]')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torchtext\\data\\field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    }
   ],
   "source": [
    "first_batch = None\n",
    "for valid_batch in iter(valid_iter):\n",
    "    # print(valid_batch.sgn)\n",
    "    # print(len(valid_batch.sgn[0]), len(valid_batch.sgn[1]))\n",
    "    # print(valid_batch.sgn[0][0], valid_batch.sgn[1][0] , len(valid_batch.sgn[0][0]))\n",
    "    first_batch = valid_batch\n",
    "    print(valid_batch)\n",
    "    break\n",
    "    \n",
    "    # batch = Batch(\n",
    "    #     is_train=False,\n",
    "    #     torch_batch=valid_batch,\n",
    "    #     txt_pad_index=txt_pad_index,\n",
    "    #     sgn_dim=sgn_dim,\n",
    "    #     use_cuda=use_cuda,\n",
    "    #     frame_subsampling_ratio=frame_subsampling_ratio,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_batch.sgn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.1970e-01, 1.7552e+00, 2.4212e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [2.3592e+00, 2.2639e+00, 4.4332e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [5.0251e+00, 2.1903e+00, 1.3583e-01,  ..., 5.7079e-02,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e-08, 1.0000e-08, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 1.0000e-08, 1.4179e+00,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [4.3050e-03, 1.0000e-08, 2.1061e+00,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[4.0923e+00, 9.2195e-02, 6.0520e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [2.0920e+00, 1.5840e-02, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 6.4240e-03, 1.0000e-08,  ..., 7.4561e-02,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.0582e+00, 1.0000e-08, 6.5102e-01,  ..., 1.0000e-08,\n",
       "          2.1270e+00, 1.0000e-08],\n",
       "         [6.3191e+00, 1.0000e-08, 6.7494e-01,  ..., 1.0000e-08,\n",
       "          1.7925e+00, 1.0000e-08],\n",
       "         [2.1337e+00, 1.0000e-08, 5.9389e-01,  ..., 1.0000e-08,\n",
       "          1.8491e+00, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[4.8486e-02, 3.4110e-01, 1.0285e-01,  ..., 1.0000e-08,\n",
       "          1.3662e+00, 1.0000e-08],\n",
       "         [2.0960e-01, 5.8419e-01, 8.9178e-02,  ..., 1.0000e-08,\n",
       "          1.4212e+00, 1.0000e-08],\n",
       "         [1.6690e+00, 6.6352e-01, 3.3390e-02,  ..., 1.0000e-08,\n",
       "          1.3840e+00, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e-08, 1.2678e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 2.7634e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 7.0646e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.sgn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_batch.sgn[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 16, 21, 17, 13, 13, 30, 17, 11, 17, 15, 13, 14, 19, 13, 19, 28, 13,\n",
       "        19, 10, 18, 28, 16,  9, 11, 16, 12, 14, 26, 16, 18, 11])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.txt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.1970e-01, 1.7552e+00, 2.4212e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [2.3592e+00, 2.2639e+00, 4.4332e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [5.0251e+00, 2.1903e+00, 1.3583e-01,  ..., 5.7079e-02,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e-08, 1.0000e-08, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 1.0000e-08, 1.4179e+00,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [4.3050e-03, 1.0000e-08, 2.1061e+00,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[4.0923e+00, 9.2195e-02, 6.0520e-01,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [2.0920e+00, 1.5840e-02, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 6.4240e-03, 1.0000e-08,  ..., 7.4561e-02,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.0582e+00, 1.0000e-08, 6.5102e-01,  ..., 1.0000e-08,\n",
       "          2.1270e+00, 1.0000e-08],\n",
       "         [6.3191e+00, 1.0000e-08, 6.7494e-01,  ..., 1.0000e-08,\n",
       "          1.7925e+00, 1.0000e-08],\n",
       "         [2.1337e+00, 1.0000e-08, 5.9389e-01,  ..., 1.0000e-08,\n",
       "          1.8491e+00, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[4.8486e-02, 3.4110e-01, 1.0285e-01,  ..., 1.0000e-08,\n",
       "          1.3662e+00, 1.0000e-08],\n",
       "         [2.0960e-01, 5.8419e-01, 8.9178e-02,  ..., 1.0000e-08,\n",
       "          1.4212e+00, 1.0000e-08],\n",
       "         [1.6690e+00, 6.6352e-01, 3.3390e-02,  ..., 1.0000e-08,\n",
       "          1.3840e+00, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e-08, 1.2678e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 2.7634e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         [1.0000e-08, 7.0646e-01, 1.0000e-08,  ..., 1.0000e-08,\n",
       "          1.0000e-08, 1.0000e-08],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.sgn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch(\n",
    "    is_train=False,\n",
    "    torch_batch=first_batch,\n",
    "    txt_pad_index=txt_pad_index,\n",
    "    sgn_dim=sgn_dim,\n",
    "    use_cuda=use_cuda,\n",
    "    frame_subsampling_ratio=frame_subsampling_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoder_output, encoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43msgn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\model.py:149\u001b[0m, in \u001b[0;36mSignModel.encode\u001b[1;34m(self, sgn, sgn_mask, sgn_length)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, sgn: Tensor, sgn_mask: Tensor, sgn_length: Tensor\n\u001b[0;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (Tensor, Tensor):\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    Encodes the source sentence.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    :return: encoder outputs (output, hidden_concat)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m--> 149\u001b[0m         embed_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgn_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msgn_mask\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    150\u001b[0m         src_length\u001b[38;5;241m=\u001b[39msgn_length,\n\u001b[0;32m    151\u001b[0m         mask\u001b[38;5;241m=\u001b[39msgn_mask,\n\u001b[0;32m    152\u001b[0m     )\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:289\u001b[0m, in \u001b[0;36mSpatialEmbeddings.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m( \u001b[38;5;28mself\u001b[39m, x: Tensor, mask: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining :\n\u001b[1;32m--> 289\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m         out\u001b[38;5;241m=\u001b[39m[]\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:276\u001b[0m, in \u001b[0;36mSpatialEmbeddings.forward_\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    273\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type:\n\u001b[1;32m--> 276\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_type \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbayesian):\n\u001b[0;32m    279\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:62\u001b[0m, in \u001b[0;36mMaskedNorm.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m     61\u001b[0m     reshaped \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features])\n\u001b[1;32m---> 62\u001b[0m     reshaped_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     63\u001b[0m     selected \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(reshaped, reshaped_mask)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m     64\u001b[0m         [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features]\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m     batch_normed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(selected)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "encoder_output, encoder_hidden = model.encode(\n",
    "                sgn=first_batch.sgn[0], sgn_mask=None, sgn_length=None\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgn_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:289\u001b[0m, in \u001b[0;36mSpatialEmbeddings.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m( \u001b[38;5;28mself\u001b[39m, x: Tensor, mask: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining :\n\u001b[1;32m--> 289\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m         out\u001b[38;5;241m=\u001b[39m[]\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:276\u001b[0m, in \u001b[0;36mSpatialEmbeddings.forward_\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    273\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type:\n\u001b[1;32m--> 276\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_type \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbayesian):\n\u001b[0;32m    279\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\strf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\CS4203 - FYP\\project folder\\Signify\\Stochastic-Transformer-Networks\\signjoey\\embeddings.py:62\u001b[0m, in \u001b[0;36mMaskedNorm.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m     61\u001b[0m     reshaped \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features])\n\u001b[1;32m---> 62\u001b[0m     reshaped_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     63\u001b[0m     selected \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(reshaped, reshaped_mask)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m     64\u001b[0m         [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features]\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m     batch_normed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(selected)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "model.sgn_embed(first_batch.sgn[0], mask=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signjoey.helpers import (\n",
    "    load_config,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from signjoey.data import load_data\n",
    "from signjoey.model import build_model\n",
    "\n",
    "\n",
    "cfg_file = 'configs/example.yaml'\n",
    "ckpt = 'output/best-kaggle.ckpt'\n",
    "\n",
    "cfg = load_config(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data, gls_vocab, txt_vocab = load_data(data_cfg=cfg[\"data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
