{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOENIX-2014-T Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwth_base_path = \"../phoenix-2014-T.v3/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px\"\n",
    "train_path = rwth_base_path + \"/train\"\n",
    "test_path = rwth_base_path + \"/test\"\n",
    "dev_path = rwth_base_path + \"/dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_files(directory, extension=\".png\"):\n",
    "    \"\"\"\n",
    "    Walks through the given directory and returns a list of file paths \n",
    "    with the specified extension (default is .png).\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    \n",
    "    image_files = [path.replace(\"\\\\\", '/') for path in image_files]\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(file_list, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"\\n\".join(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image paths\n",
    "train_files = get_image_files(train_path)\n",
    "save_to_txt(train_files, 'train_images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev image paths\n",
    "dev_files = get_image_files(dev_path)\n",
    "save_to_txt(dev_files, 'dev_images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image paths\n",
    "test_files = get_image_files(test_path)\n",
    "save_to_txt(test_files, 'test_images.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RTMPose Keypoints Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = \"Models/rtmpose_onnx/rtmw-x_simcc-cocktail13_pt-ucoco_270e-384x288-0949e3a9_20230925/end2end.onnx\"\n",
    "pose_input_size = (288, 384)\n",
    "det = \"Models/yolox_onnx/yolox_x_8xb8-300e_humanart-a39d44ed/end2end.onnx\"\n",
    "det_input_size = (640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from rtmlib import Wholebody, draw_skeleton\n",
    "\n",
    "device = 'cpu'  # cpu, cuda, mps\n",
    "backend = 'onnxruntime'  # opencv, onnxruntime, openvino\n",
    "openpose_skeleton = False  # True for openpose-style, False for mmpose-style\n",
    "\n",
    "wholebody = Wholebody(to_openpose=openpose_skeleton,\n",
    "                      det = det ,\n",
    "                      det_input_size = det_input_size,\n",
    "                      pose = pose,\n",
    "                      pose_input_size = pose_input_size,\n",
    "                      mode='balanced',  # 'performance', 'lightweight', 'balanced'. Default: 'balanced'\n",
    "                      backend=backend, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "def extract_keypoints(image_files, output_file, start_idx=0, end_idx=None, batch_size=500):\n",
    "    \"\"\"\n",
    "    Extract keypoints for a list of images and save them to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_files: List of image file paths.\n",
    "    - output_file: Path of the JSON file to save the extracted keypoints.\n",
    "    - start_idx: Starting index for the image files list.\n",
    "    - end_idx: Ending index for the image files list (None to process all files).\n",
    "    - batch_size: Save to the JSON file every 'batch_size' images processed.\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(image_files)\n",
    "    \n",
    "    keypoints_data = []\n",
    "    \n",
    "    for i in range(start_idx, end_idx):\n",
    "        img = cv2.imread(image_files[i])\n",
    "        keypoints, scores = wholebody(img)\n",
    "        \n",
    "        data = {\n",
    "            \"path\": image_files[i],\n",
    "            \"keypoints\": keypoints.tolist(),\n",
    "            \"scores\": scores.tolist()\n",
    "        }\n",
    "        keypoints_data.append(data)\n",
    "\n",
    "        # Log progress and save intermediate results in batches\n",
    "        if i % batch_size == 0:\n",
    "            print(f\"Processed {i} images.\")\n",
    "            with open(output_file, 'w') as json_file:\n",
    "                json.dump(keypoints_data, json_file)\n",
    "\n",
    "    # Save the final batch of data\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(keypoints_data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(filename):\n",
    "\n",
    "  with open(filename, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  lines = [line.rstrip() for line in lines]\n",
    "\n",
    "  return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train images keypoints\n",
    "train_files = read_file_to_list(\"train_images.txt\")\n",
    "\n",
    "train_output_file = \"./rwth_train_keypoints.json\"\n",
    "extract_keypoints(train_files, train_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dev images keypoints\n",
    "dev_files = read_file_to_list(\"dev_images.txt\")\n",
    "\n",
    "dev_output_file = \"./rwth_dev_keypoints.json\"\n",
    "extract_keypoints(dev_files, dev_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test images keypoints\n",
    "test_files = read_file_to_list(\"test_images.txt\")\n",
    "\n",
    "test_output_file = \"./rwth_test_keypoints.json\"\n",
    "extract_keypoints(test_files, test_output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
